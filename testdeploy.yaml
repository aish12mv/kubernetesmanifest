apiVersion: "serving.kserve.io/v1beta1"
kind: "InferenceService"
metadata:
  labels:
    app: keyphrase
    version: v2
  name: "keyphrase"
  annotations:
    prometheus.io/scrape: 'true'
    prometheus.io/port: '9090'
spec:
  predictor:
    minReplicas: 0
    logger:
      mode: all
      url: http://message-dumper.default/
    pytorch:
      image: gcr.io/hclsw-gcp-xai/kwe-custom-predictor-xai:v5
      resources:
         requests:
            cpu: "124m"
            memory: "2Gi"
         limits:
            memory: "4Gi"
            
